Week 1:
  - 1.1: What is a neural network
  - 1.2: Supervised Learning with Neural Networks
  - 1.3: Why is Deep Learning taking off
  
Week 2: Neural Networks Basics
  - Logistic Regression as a Neural Network
    - Binary Classification
    - Logistic Regression
    - Logistic Regression Cost Function
    - Gradient Descent
    - Derivatives
    - More Derivative Examples
    - Computation graph
    - Derivatives with a Computation Graph
    - Logistic Regression Gradient Descent
    - Gradient Descent on m Examples
  - Python and Vectorization  
    - Vectorization
    - More Vectorization Examples
    - Vectorizing Logistic Regression
    - Vectorizing Logistic Regression's Gradient Output
    - Broadcasting in Python
    - A note on python/numpy vectors
    - Quick tour of Jupyter/iPython Notebooks
    - Explanation of logistic regression cost function (optional)

Week 3: Shallow Neural Network
  - Neural Networks Overview
  - Neural Network Representation
  - Computing a Neural Network's Output
  - Vectorizing across multiple examples
  - Explanation for Vectorized Implementation
  - Activation functions
  - Why do you need non-linear activation functions?
  - Derivatives of activation functions
  - Gradient descent for Neural Networks
  - Backpropagation intuition (optional)
  - Random Initialization
  
Week 4: Deep Neural Networks
  - Deep L-layer neural network
  - Forward Propagation in a Deep Network
  - Getting your matrix dimensions right1
  - Why deep representations?
  - Building blocks of deep neural networks
  - Forward and Backward Propagation
  - Parameters vs Hyperparameters
  - What does this have to do with the brain?
